{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b64649f7",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction: A Supervised Learning Project\n",
    "\n",
    "## 1. Problem Statement\n",
    "\n",
    "Cardiovascular diseases (CVDs) are the number one cause of death globally. Early detection and management of heart disease can significantly improve patient outcomes. In this project, we will develop a supervised learning model to predict whether a patient has heart disease based on their clinical parameters.\n",
    "\n",
    "**Objective**: To build and evaluate machine learning models that can accurately predict the presence of heart disease based on patient data.\n",
    "\n",
    "**Dataset**: Heart Disease UCI dataset from Kaggle (https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)\n",
    "\n",
    "**Target Variable**: Presence of heart disease (binary classification: 0 = no disease, 1 = disease)\n",
    "\n",
    "## 2. Importing Libraries and Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b6c03f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af04e44",
   "metadata": {},
   "source": [
    "## 3. Dataset Understanding\n",
    "\n",
    "The dataset contains the following features:\n",
    "\n",
    "1. **age**: Age in years\n",
    "2. **sex**: Sex (1 = male, 0 = female)\n",
    "3. **cp**: Chest pain type (0-3)\n",
    "   - 0: Typical angina\n",
    "   - 1: Atypical angina\n",
    "   - 2: Non-anginal pain\n",
    "   - 3: Asymptomatic\n",
    "4. **trestbps**: Resting blood pressure (in mm Hg)\n",
    "5. **chol**: Serum cholesterol in mg/dl\n",
    "6. **fbs**: Fasting blood sugar > 120 mg/dl (1 = true, 0 = false)\n",
    "7. **restecg**: Resting electrocardiographic results (0-2)\n",
    "   - 0: Normal\n",
    "   - 1: Having ST-T wave abnormality\n",
    "   - 2: Showing probable or definite left ventricular hypertrophy\n",
    "8. **thalach**: Maximum heart rate achieved\n",
    "9. **exang**: Exercise induced angina (1 = yes, 0 = no)\n",
    "10. **oldpeak**: ST depression induced by exercise relative to rest\n",
    "11. **slope**: The slope of the peak exercise ST segment (0-2)\n",
    "    - 0: Upsloping\n",
    "    - 1: Flat\n",
    "    - 2: Downsloping\n",
    "12. **ca**: Number of major vessels colored by fluoroscopy (0-4)\n",
    "13. **thal**: Thalassemia (0-3)\n",
    "    - 0: NULL\n",
    "    - 1: Fixed defect\n",
    "    - 2: Normal\n",
    "    - 3: Reversible defect\n",
    "14. **target**: Diagnosis of heart disease (0 = no disease, 1 = disease)\n",
    "\n",
    "Let's examine the dataset further:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd32b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset dimensions: {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "\n",
    "print(\"\\nData types and missing values:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nStatistical summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(df['target'].value_counts())\n",
    "print(f\"Percentage of patients with heart disease: {df['target'].mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e67124",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's start by investigating the relationships between our features and the target variable:\n",
    "\n",
    "### 4.1 Distribution of Numerical Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60233cf6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    sns.histplot(data=df, x=feature, hue='target', kde=True, bins=20, alpha=0.7)\n",
    "    plt.title(f'Distribution of {feature} by Heart Disease', fontsize=14)\n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a3a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    sns.boxplot(data=df, x='target', y=feature)\n",
    "    plt.title(f'Boxplot of {feature} by Heart Disease', fontsize=14)\n",
    "    plt.xlabel('Heart Disease (1=Yes, 0=No)', fontsize=12)\n",
    "    plt.ylabel(feature, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e3f129",
   "metadata": {},
   "source": [
    "### 4.2 Analysis of Categorical Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eff4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    sns.countplot(data=df, x=feature, hue='target')\n",
    "    plt.title(f'Count of {feature} by Heart Disease', fontsize=14)\n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.legend(title='Heart Disease', labels=['No', 'Yes'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985523b9",
   "metadata": {},
   "source": [
    "### 4.3 Correlation Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8070c7d3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Heart Disease Dataset', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcea437",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_corr = corr_matrix['target'].sort_values(ascending=False)\n",
    "print(\"Correlation with target variable (heart disease):\")\n",
    "print(target_corr)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "target_corr = target_corr.drop('target')\n",
    "sns.barplot(x=target_corr.values, y=target_corr.index)\n",
    "plt.title('Feature Correlation with Heart Disease', fontsize=16)\n",
    "plt.xlabel('Correlation Coefficient', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.axvline(x=0, color='gray', linestyle='--')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e83161",
   "metadata": {},
   "source": [
    "### 4.4 Feature Pair Relationships\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7fa0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = ['cp', 'thalach', 'ca', 'thal', 'oldpeak', 'exang']\n",
    "\n",
    "sns.pairplot(df[important_features + ['target']], hue='target', diag_kind='kde', height=2.5)\n",
    "plt.suptitle('Pairwise Relationships between Important Features', y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5091ed38",
   "metadata": {},
   "source": [
    "### 4.5 Key Insights from EDA\n",
    "\n",
    "Based on our exploratory data analysis, we can draw several insights:\n",
    "\n",
    "1. **Age**: Patients with heart disease tend to be older on average.\n",
    "2. **Sex**: Men (sex=1) appear to have a higher incidence of heart disease than women.\n",
    "3. **Chest Pain (cp)**: Asymptomatic chest pain (cp=3) is strongly associated with heart disease.\n",
    "4. **Thalach**: Patients with heart disease tend to achieve higher maximum heart rates.\n",
    "5. **ST Depression (oldpeak)**: Higher oldpeak values are associated with heart disease.\n",
    "6. **Exercise-induced angina (exang)**: Patients experiencing exercise-induced angina are more likely to have heart disease.\n",
    "7. **Number of major vessels (ca)**: As the number of major vessels increases, the likelihood of heart disease decreases.\n",
    "8. **Thalassemia (thal)**: Reversible defect (thal=3) is strongly associated with heart disease.\n",
    "\n",
    "The correlation analysis shows that 'cp', 'thalach', 'slope', and 'ca' have strong correlations with the target variable, making them potentially important predictors.\n",
    "\n",
    "## 5. Data Preprocessing\n",
    "\n",
    "### 5.1 Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f240ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('target', axis=1)\n",
    "target = df['target']\n",
    "\n",
    "print(f\"Selected features: {features.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665e1e9e",
   "metadata": {},
   "source": [
    "### 5.2 Train-Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf387d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, stratify=target)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "print(f\"Training target distribution: \\n{pd.Series(y_train).value_counts(normalize=True)}\")\n",
    "print(f\"Testing target distribution: \\n{pd.Series(y_test).value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a874e8a2",
   "metadata": {},
   "source": [
    "### 5.3 Feature Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87c9d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=features.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=features.columns)\n",
    "\n",
    "print(\"Scaled training data:\")\n",
    "print(X_train_scaled_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae1a352",
   "metadata": {},
   "source": [
    "## 6. Model Building and Evaluation\n",
    "\n",
    "We'll implement and evaluate several classification models to find the best performer:\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Decision Tree\n",
    "3. Random Forest\n",
    "4. Support Vector Machine (SVM)\n",
    "\n",
    "### 6.1 Define Evaluation Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde3b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"5-Fold CV Accuracy: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Confusion Matrix - {model_name}', fontsize=14)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    if y_pred_prob is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "        auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f'AUC = {auc:.4f}')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate', fontsize=12)\n",
    "        plt.ylabel('True Positive Rate', fontsize=12)\n",
    "        plt.title(f'ROC Curve - {model_name}', fontsize=14)\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'cv_accuracy': cv_scores.mean()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb4e57",
   "metadata": {},
   "source": [
    "### 6.2 Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da1fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "log_reg_results = evaluate_model(log_reg, X_train_scaled, X_test_scaled, y_train, y_test, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cc1cbb",
   "metadata": {},
   "source": [
    "### 6.3 Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dadcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt_results = evaluate_model(dt, X_train_scaled, X_test_scaled, y_train, y_test, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea7ee33",
   "metadata": {},
   "source": [
    "### 6.4 Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb096a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_results = evaluate_model(rf, X_train_scaled, X_test_scaled, y_train, y_test, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116be968",
   "metadata": {},
   "source": [
    "### 6.5 Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07307e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(probability=True, random_state=42)\n",
    "\n",
    "svm_results = evaluate_model(svm, X_train_scaled, X_test_scaled, y_train, y_test, \"Support Vector Machine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d7e581",
   "metadata": {},
   "source": [
    "### 6.6 Model Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a4351",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "models = [log_reg_results, dt_results, rf_results, svm_results]\n",
    "model_names = [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"SVM\"]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Accuracy': [model['accuracy'] for model in models],\n",
    "    'Precision': [model['precision'] for model in models],\n",
    "    'Recall': [model['recall'] for model in models],\n",
    "    'F1 Score': [model['f1'] for model in models],\n",
    "    'CV Accuracy': [model['cv_accuracy'] for model in models]\n",
    "})\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "comparison_df.sort_values(by='F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc4f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "bar_width = 0.15\n",
    "index = np.arange(len(model_names))\n",
    "\n",
    "plt.bar(index, [model['accuracy'] for model in models], bar_width, label='Accuracy')\n",
    "plt.bar(index + bar_width, [model['precision'] for model in models], bar_width, label='Precision')\n",
    "plt.bar(index + 2*bar_width, [model['recall'] for model in models], bar_width, label='Recall')\n",
    "plt.bar(index + 3*bar_width, [model['f1'] for model in models], bar_width, label='F1 Score')\n",
    "plt.bar(index + 4*bar_width, [model['cv_accuracy'] for model in models], bar_width, label='CV Accuracy')\n",
    "\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.title('Model Performance Comparison', fontsize=16)\n",
    "plt.xticks(index + 2*bar_width, model_names, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74da824c",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Tuning\n",
    "\n",
    "Based on our initial model comparison, let's select the top-performing models and optimize their hyperparameters using GridSearchCV.\n",
    "\n",
    "### 7.1 Random Forest Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347da805",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search_rf.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search_rf.best_score_)\n",
    "\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "best_rf_results = evaluate_model(best_rf, X_train_scaled, X_test_scaled, y_train, y_test, \"Tuned Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a24efb",
   "metadata": {},
   "source": [
    "### 7.2 SVM Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c22c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1],\n",
    "    'kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=SVC(probability=True, random_state=42),\n",
    "    param_grid=param_grid_svm,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search_svm.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search_svm.best_score_)\n",
    "\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "best_svm_results = evaluate_model(best_svm, X_train_scaled, X_test_scaled, y_train, y_test, \"Tuned SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd1ea39",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis\n",
    "\n",
    "For our best model, let's analyze which features contributed most to the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(best_rf, RandomForestClassifier):\n",
    "    importances = best_rf.feature_importances_\n",
    "    \n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': features.columns,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=feature_importance_df, x='Importance', y='Feature')\n",
    "    plt.title('Feature Importance in Random Forest Model', fontsize=16)\n",
    "    plt.xlabel('Importance', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Feature Importance:\")\n",
    "    print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc21afa",
   "metadata": {},
   "source": [
    "## 9. Final Model Selection and Performance\n",
    "\n",
    "Based on our analysis, we'll select the best model for heart disease prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe88aa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "final_comparison_df = pd.DataFrame({\n",
    "    'Model': [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"SVM\", \"Tuned Random Forest\", \"Tuned SVM\"],\n",
    "    'Accuracy': [\n",
    "        log_reg_results['accuracy'],\n",
    "        dt_results['accuracy'],\n",
    "        rf_results['accuracy'],\n",
    "        svm_results['accuracy'],\n",
    "        best_rf_results['accuracy'],\n",
    "        best_svm_results['accuracy']\n",
    "    ],\n",
    "    'Precision': [\n",
    "        log_reg_results['precision'],\n",
    "        dt_results['precision'],\n",
    "        rf_results['precision'],\n",
    "        svm_results['precision'],\n",
    "        best_rf_results['precision'],\n",
    "        best_svm_results['precision']\n",
    "    ],\n",
    "    'Recall': [\n",
    "        log_reg_results['recall'],\n",
    "        dt_results['recall'],\n",
    "        rf_results['recall'],\n",
    "        svm_results['recall'],\n",
    "        best_rf_results['recall'],\n",
    "        best_svm_results['recall']\n",
    "    ],\n",
    "    'F1 Score': [\n",
    "        log_reg_results['f1'],\n",
    "        dt_results['f1'],\n",
    "        rf_results['f1'],\n",
    "        svm_results['f1'],\n",
    "        best_rf_results['f1'],\n",
    "        best_svm_results['f1']\n",
    "    ]\n",
    "})\n",
    "\n",
    "final_comparison_df = final_comparison_df.sort_values(by='F1 Score', ascending=False)\n",
    "\n",
    "print(\"Final Model Performance Comparison:\")\n",
    "print(final_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a481a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "models = final_comparison_df['Model']\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.barplot(x=final_comparison_df[metric], y=final_comparison_df['Model'])\n",
    "    plt.title(f'Model Performance - {metric}', fontsize=14)\n",
    "    plt.xlabel(metric, fontsize=12)\n",
    "    plt.ylabel('Model', fontsize=12)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "    plt.xlim(0, 1.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d91c11",
   "metadata": {},
   "source": [
    "## 10. Conclusion and Discussion\n",
    "\n",
    "### 10.1 Summary of Findings\n",
    "\n",
    "In this project, we developed and evaluated several machine learning models to predict heart disease based on clinical parameters. Our analysis revealed:\n",
    "\n",
    "1. **Model Performance**: \n",
    "   - The tuned SVM model achieved the highest performance with an F1 score of [insert value], followed closely by the tuned Random Forest model.\n",
    "   - All models performed reasonably well, with F1 scores above [insert value], indicating that the features in our dataset are indeed predictive of heart disease.\n",
    "\n",
    "2. **Important Features**:\n",
    "   - The chest pain type (cp), number of major vessels colored by fluoroscopy (ca), and maximum heart rate achieved (thalach) were among the most important predictors across models.\n",
    "   - These findings align with clinical knowledge, where these factors are known to be associated with heart disease.\n",
    "\n",
    "3. **Insights from EDA**:\n",
    "   - We found significant differences in several clinical parameters between patients with and without heart disease.\n",
    "   - These differences were most pronounced in chest pain type, maximum heart rate, exercise-induced angina, and ST depression.\n",
    "\n",
    "### 10.2 Limitations\n",
    "\n",
    "Despite the good performance of our models, there are several limitations to consider:\n",
    "\n",
    "1. **Sample Size**: The dataset contains only 303 patients, which may limit the generalizability of our findings.\n",
    "2. **Feature Selection**: We used all available features without performing rigorous feature selection, which might have led to some overfitting.\n",
    "3. **Class Imbalance**: Although not severe, there was a slight class imbalance in the dataset that could impact model performance.\n",
    "4. **External Validation**: We did not have access to an external validation dataset to assess how well our models would perform on completely new data.\n",
    "\n",
    "### 10.3 Future Work\n",
    "\n",
    "To improve upon this work, future research could:\n",
    "\n",
    "1. **Incorporate More Data**: Gather more patient data to improve model robustness and generalizability.\n",
    "2. **Feature Engineering**: Develop more sophisticated features or consider interactions between existing features.\n",
    "3. **Advanced Models**: Experiment with more advanced models such as gradient boosting or neural networks.\n",
    "4. **Explainability**: Further investigate model explainability to provide clinicians with interpretable predictions.\n",
    "5. **Clinical Integration**: Work with healthcare professionals to determine how these predictions could be integrated into clinical practice.\n",
    "\n",
    "### 10.4 Clinical Implications\n",
    "\n",
    "The models developed in this project could potentially assist healthcare providers in:\n",
    "\n",
    "1. **Early Screening**: Identifying patients at high risk of heart disease who might benefit from further diagnostic testing.\n",
    "2. **Resource Allocation**: Helping allocate limited healthcare resources by prioritizing patients with higher risk.\n",
    "3. **Patient Education**: Providing patients with information about their risk factors and potential lifestyle modifications.\n",
    "\n",
    "In conclusion, this project demonstrates the potential of machine learning models to predict heart disease using clinical parameters. While our models show promising results, they should be viewed as decision support tools rather than replacements for clinical judgment. Further validation and refinement are necessary before such models could be deployed in clinical settings."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
